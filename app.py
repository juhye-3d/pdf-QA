# streamlit_pdf_rag_tfidf.py

import streamlit as st
import requests
import io
from PyPDF2 import PdfReader
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# OpenAI API í‚¤ ì…ë ¥
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
def get_pdf_text_from_url(url: str) -> str:
    try:
        response = requests.get(url)
        response.raise_for_status()
        with io.BytesIO(response.content) as f:
            reader = PdfReader(f)
            text = ""
            for page in reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
            return text.strip()
    except Exception as e:
        return f"[PDF ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨] {e}"

# ìŠ¬ë¼ì´ë”© ë¶„í• 
def split_text(text, chunk_size=3000, overlap=300):
    chunks = []
    start = 0
    while start < len(text):
        end = min(start + chunk_size, len(text))
        chunk = text[start:end]
        chunks.append(chunk.strip())
        start += chunk_size - overlap
    return chunks

# TF-IDF ê¸°ë°˜ ìœ ì‚¬ chunk ì¶”ì¶œ
def get_most_similar_chunks(query, chunks, top_n=2):
    corpus = chunks + [query]  # ì „ì²´ ë¬¸ì„œ chunk + ì§ˆë¬¸
    vectorizer = TfidfVectorizer().fit_transform(corpus)
    cosine_sim = cosine_similarity(vectorizer[-1], vectorizer[:-1])  # ì§ˆë¬¸ vs chunks
    sim_scores = cosine_sim.flatten()
    top_indices = sim_scores.argsort()[::-1][:top_n]
    return [chunks[i] for i in top_indices]

# GPT ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
def stream_gpt_response(prompt: str):
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹ ë¢°ë„ ë†’ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=700,
        temperature=0.3,
        stream=True
    )
    full_response = ""
    for chunk in response:
        delta = chunk.choices[0].delta.get("content", "")
        full_response += delta
        yield delta
    return full_response

# --- Streamlit UI ---
st.set_page_config(page_title="ğŸ“„ PDF GPT Q&A (with TF-IDF)", layout="centered")
st.title("ğŸ“„ PDF ê¸°ë°˜ GPT Q&A (TF-IDF ê¸°ë°˜ Chunk ì¶”ì¶œ)")

pdf_url = st.text_input("ğŸ”— PDF ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”", 
    value="https://www.themoonlight.io/file?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2501.00539")

# PDF ë¡œë”©
if st.button("ğŸ“¥ PDF ë¶ˆëŸ¬ì˜¤ê¸°"):
    with st.spinner("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤..."):
        full_text = get_pdf_text_from_url(pdf_url)

    if full_text.startswith("[PDF ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨]"):
        st.error(full_text)
    else:
        st.success("âœ… PDF ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
        st.text_area("ğŸ“„ ì¼ë¶€ ë¯¸ë¦¬ë³´ê¸°", full_text[:1000], height=200)

        # chunk ë¶„í• 
        chunks = split_text(full_text)
        st.write(f"ğŸ” ì´ {len(chunks)}ê°œ chunkë¡œ ë¶„í• ë¨")

        # ì§ˆë¬¸
        question = st.text_input("â“ GPTì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”", value="ì´ ë…¼ë¬¸ì˜ í•µì‹¬ì€ ë¬´ì—‡ì¸ê°€ìš”?")

        if st.button("ğŸ” ì§ˆë¬¸í•˜ê¸°"):
            with st.spinner("ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ” chunkë¥¼ ì°¾ëŠ” ì¤‘..."):
                top_chunks = get_most_similar_chunks(question, chunks, top_n=2)
                context = "\n\n".join(top_chunks)
                prompt = f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:\n\n{context}\n\nì§ˆë¬¸: {question}"

            st.markdown("#### ğŸ’¬ GPT ì‘ë‹µ:")
            placeholder = st.empty()
            result = ""
            for chunk in stream_gpt_response(prompt):
                result += chunk
                placeholder.markdown(result)
